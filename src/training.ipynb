{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 16:56:25.920150: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-02 16:56:26.515738: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:56:26.515783: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-02 16:56:26.597706: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-02 16:56:28.824787: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:56:28.824966: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:56:28.824980: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset from test audio file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 1024, 169)\n"
     ]
    }
   ],
   "source": [
    "xf, X = create_dataset('audio/training_audio.wav', 2, 0.5)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some 'blocks' of NN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(inputs, input_shape, channels, block_name='ResBlock'):\n",
    "    \n",
    "    conv2d_1 = keras.layers.Conv2D(channels, kernel_size=(10, 1), padding='same', input_shape=input_shape)(inputs)\n",
    "\n",
    "    batch_norm_1 = keras.layers.BatchNormalization()(conv2d_1)\n",
    "    activation_1 = keras.layers.Activation('relu')(batch_norm_1)\n",
    "\n",
    "    conv2d_2 = keras.layers.Conv2D(channels, kernel_size=10, padding='same')(activation_1)\n",
    "    batch_norm_2 = keras.layers.BatchNormalization()(conv2d_2)\n",
    "\n",
    "    add = keras.layers.Add()([batch_norm_2, inputs])\n",
    "    activation_2 = keras.layers.Activation('relu')(add)\n",
    "    return activation_2\n",
    "\n",
    "def downscale_block(inputs, num_filters, block_name='DownscaleBlock'):\n",
    "\n",
    "    downscale = keras.layers.Conv2D(num_filters, kernel_size=(10, 1), padding='same')(inputs)\n",
    "    batch_norm = keras.layers.BatchNormalization()(downscale)\n",
    "    activation = keras.layers.Activation('relu')(batch_norm)\n",
    "    \n",
    "    return activation\n",
    "\n",
    "def upscale_block(inputs, target_size, num_filters, block_name='UpscaleBlock'):\n",
    "    \n",
    "    _, height, timesteps, channels = inputs.shape\n",
    "    upscale = keras.layers.Conv2DTranspose(num_filters, (target_size - height + 1, 1))(inputs)\n",
    "    batch_norm = keras.layers.BatchNormalization()(upscale)\n",
    "    activation = keras.layers.Activation('relu')(batch_norm)\n",
    "\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_lstm_decoder(spec_shape, start_filters):\n",
    "    input_length =  spec_shape[0]\n",
    "    time_steps = spec_shape[1]\n",
    "    input_shape = (input_length, time_steps, 1)\n",
    "\n",
    "    # Encoder\n",
    "    inputs = keras.layers.Input(input_shape)                                                                    # input_length is power of two\n",
    "    print(input_shape)\n",
    "\n",
    "    res_block_1 = residual_block(inputs, input_shape, 1, 'ResBlock1')\n",
    "    max_pool_1 = keras.layers.MaxPool2D(pool_size=(2,1))(res_block_1)                 # (input_length/2,)\n",
    "    down_scale_1 = downscale_block(max_pool_1, start_filters, 'DownscaleBlock1')\n",
    "    print(down_scale_1.shape)\n",
    "\n",
    "    res_block_2 = residual_block(down_scale_1, (input_length//2, time_steps, start_filters), start_filters, 'ResBlock2')\n",
    "    max_pool_2 = keras.layers.MaxPool2D(pool_size=(2,1))(res_block_2)                 # (input_length/2,)\n",
    "    down_scale_2 = downscale_block(max_pool_2, start_filters * 2, 'DownscaleBlock2')\n",
    "    print(down_scale_2.shape)\n",
    "\n",
    "    res_block_3 = residual_block(down_scale_2, (input_length//4, time_steps, start_filters*2), start_filters * 2, 'ResBlock3')\n",
    "    max_pool_3 = keras.layers.MaxPool2D(pool_size=(2,1))(res_block_2)                 # (input_length/2,)\n",
    "    down_scale_3 = downscale_block(max_pool_3, start_filters * 4, 'DownscaleBlock3')\n",
    "    print(down_scale_3.shape)\n",
    "\n",
    "    res_block_4 = residual_block(down_scale_3, (input_length//8, time_steps, start_filters*4), start_filters * 4, 'ResBlock4')\n",
    "    max_pool_4 = keras.layers.MaxPool2D(pool_size=(2,1))(res_block_4)                 # (input_length/2,)\n",
    "    down_scale_4 = downscale_block(max_pool_4, start_filters * 8, 'DownscaleBlock4')\n",
    "    print(down_scale_4.shape)\n",
    "\n",
    "    # Decoder\n",
    "    _, height, timesteps, channels = down_scale_4.shape\n",
    "    # down_scale_4_flat = tf.reshape(down_scale_4, (-1, timesteps, height * channels))\n",
    "    down_scale_4_flat = keras.layers.Reshape((timesteps, height * channels))(down_scale_4)\n",
    "    print(f\"down_scale_4 {down_scale_4_flat.shape}\")\n",
    "    lstm = keras.layers.LSTM(height * channels, return_sequences=True)(down_scale_4_flat)    # todo CHANGE N UNITS\n",
    "\n",
    "    print(f\"LSTM: {lstm.shape}\")\n",
    "\n",
    "    # lstm_unflatten = tf.reshape(lstm, (-1, height, timesteps, channels))\n",
    "    lstm_unflatten = keras.layers.Reshape((height, timesteps, channels))(lstm)\n",
    "    print(f\"Unflattened LSTM: {lstm_unflatten.shape}\")\n",
    "\n",
    "    upscale_1 = upscale_block(lstm_unflatten, input_length//8, start_filters * 4, 'Upscale1')\n",
    "    print(upscale_1.shape)\n",
    "    upscale_2 = upscale_block(upscale_1, input_length//4, start_filters * 2, 'Upscale2')\n",
    "    print(upscale_2.shape)\n",
    "    upscale_3 = upscale_block(upscale_2, input_length//2, start_filters, 'Upscale3')\n",
    "    print(upscale_3.shape)\n",
    "    upscale_4 = upscale_block(upscale_3, input_length, 1, 'Upscale4')\n",
    "    print(upscale_4.shape)\n",
    "\n",
    "    _, height, timesteps, channels = upscale_4.shape\n",
    "    # outputs = tf.reshape(upscale_4, (-1, height, timesteps))\n",
    "    outputs = keras.layers.Reshape((height, timesteps))(upscale_4)\n",
    "    print(outputs.shape)\n",
    "    \n",
    "    # outputs = keras.layers.Dense(input_length, activation='sigmoid')(upscale_4_flatten)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 169, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 16:57:10.946703: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-10-02 16:57:10.949543: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:57:10.949606: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:57:10.949646: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:57:10.949698: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:57:10.949777: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:57:10.949825: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:57:10.949887: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:57:10.949939: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-10-02 16:57:10.949966: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-02 16:57:10.951591: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 512, 169, 8)\n",
      "(None, 256, 169, 16)\n",
      "(None, 256, 169, 32)\n",
      "(None, 128, 169, 64)\n",
      "down_scale_4 (None, 169, 8192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-02 16:57:11.275702: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1073741824 exceeds 10% of free system memory.\n",
      "2022-10-02 16:57:11.621254: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1073741824 exceeds 10% of free system memory.\n",
      "2022-10-02 16:57:11.916649: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1073741824 exceeds 10% of free system memory.\n",
      "2022-10-02 16:57:12.225200: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1073741824 exceeds 10% of free system memory.\n",
      "2022-10-02 16:57:12.672631: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1073741824 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "model = encoder_lstm_decoder(X[0].shape, 8)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                       tf.keras.metrics.FalseNegatives()])\n",
    "print(X.shape)\n",
    "X = X[:2]\n",
    "# print(model.summary())\n",
    "model.fit(x=X, y=X, epochs=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
