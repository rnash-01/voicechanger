{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# from https://medium.com/ibm-data-ai/memory-hygiene-with-tensorflow-during-model-training-and-deployment-for-inference-45cf49a15688\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(str(gpu))\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpu,[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset from test audio file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf, X, spec_params = create_dataset('audio/training_audio.wav', 2, 0.5)\n",
    "print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input((1024, 256, 1))\n",
    "\n",
    "# Encoder\n",
    "batchnorm = layers.BatchNormalization()(inputs)\n",
    "conv = layers.Conv2D(2, (3, 3), (1, 1), padding='same', activation='relu')(batchnorm)\n",
    "pool = layers.MaxPool2D((2, 2), strides=2)(conv)\n",
    "batchnorm = layers.BatchNormalization()(pool)\n",
    "conv = layers.Conv2D(4, (3, 3), (1, 1), padding='same', activation='relu')(pool)\n",
    "pool = layers.MaxPool2D((2, 2), strides=2)(conv)\n",
    "batchnorm = layers.BatchNormalization()(pool)\n",
    "conv = layers.Conv2D(8, (3, 3), (1, 1), padding='same', activation='relu')(pool)\n",
    "pool = layers.MaxPool2D((2, 2), strides=2)(conv)\n",
    "batchnorm = layers.BatchNormalization()(pool)\n",
    "conv = layers.Conv2D(16, (3, 3), (1, 1), padding='same', activation='relu')(pool)\n",
    "pool = layers.MaxPool2D((2, 2), strides=2)(conv)\n",
    "batchnorm = layers.BatchNormalization()(pool)\n",
    "conv = layers.Conv2D(32, (3, 3), (1, 1), padding='same', activation='relu')(pool)\n",
    "pool = layers.MaxPool2D((2, 2), strides=2)(conv)\n",
    "batchnorm = layers.BatchNormalization()(pool)\n",
    "conv = layers.Conv2D(64, (3, 3), (1, 1), padding='same', activation='relu')(pool)\n",
    "pool = layers.MaxPool2D((2, 2), strides=2)(conv)\n",
    "batchnorm = layers.BatchNormalization()(pool)\n",
    "\n",
    "flatten = layers.Flatten()(pool)\n",
    "dense = layers.Dense(2048)(flatten)\n",
    "\n",
    "# Decoder\n",
    "dense2 = layers.Dense(flatten.shape[1])(dense)\n",
    "reshaped = layers.Reshape(pool.shape[1:])(dense2)\n",
    "\n",
    "filters = 64\n",
    "deconv = reshaped\n",
    "while (filters > 2):\n",
    "    print(filters)\n",
    "    batchnorm = layers.BatchNormalization()(deconv)\n",
    "    depool = layers.Conv2DTranspose(filters, (2, 2), strides=2)(batchnorm)\n",
    "    deconv = layers.Conv2DTranspose(1, (3, 3), strides=1, padding='same', activation='relu')(depool)\n",
    "    filters /= 2\n",
    "\n",
    "depool = layers.Conv2DTranspose(filters, (2, 2), strides=2)(deconv)\n",
    "deconv = layers.Conv2DTranspose(1, (3, 3), strides=1, padding='same', activation='sigmoid')(depool)\n",
    "\n",
    "print(deconv.shape)\n",
    "\n",
    "outputs = deconv\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit = tf.expand_dims(X, -1)\n",
    "X_fit = (X_fit - np.min(X_fit))/(np.max(X_fit) - np.min(X_fit))\n",
    "\n",
    "print(\"==================\")\n",
    "print(X_fit.shape)\n",
    "print(\"==================\")\n",
    "\n",
    "model.load_weights(\"cnn_autoencoder\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_fit, X_fit,\n",
    "        epochs=150,\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARE SPECTROGRAMS IN IMAGES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_example = X[0]\n",
    "\n",
    "plt.imsave(\"INPUT_EXAMPLE.png\", x_example)\n",
    "x_example = np.reshape(x_example, (1, x_example.shape[0], x_example.shape[1], 1))\n",
    "print(x_example.shape)\n",
    "prediction = model.predict(x_example)\n",
    "plt.imsave(\"OUTPUT_EXAMPLE.png\", prediction[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_autoencoder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(postprocessing)\n",
    "out_samp, out_win, out_stride = spec_params\n",
    "postprocessing.reverse_spectrogram(prediction[0, :, :, 0], out_samp, out_win, out_stride)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del spectrogram\n",
    "del spectrogram_timestep"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 21 2022, 23:50:54) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cc8f092f77316f6fee317f7cf3b29c6fa2dc86058ef2ab119f209826031bc14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
