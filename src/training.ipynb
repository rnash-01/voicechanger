{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-04 15:33:44.030418: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-04 15:33:44.277439: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-04 15:33:45.283946: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-04 15:33:45.284099: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-04 15:33:45.284113: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-04 15:33:46.940126: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 15:33:46.979259: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-04 15:33:46.980446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# from https://medium.com/ibm-data-ai/memory-hygiene-with-tensorflow-during-model-training-and-deployment-for-inference-45cf49a15688\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(str(gpu))\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpu,[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset from test audio file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xf, X, spec_params = create_dataset('audio/training_audio.wav', 2, 0.5)\n",
    "X = np.abs(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 4)\n",
      "(None, 256, 256, 4)\n",
      "(None, 256, 256, 2)\n",
      "(None, 256, 512, 2)\n",
      "(None, 256, 512, 2)\n",
      "(None, 256, 512, 2)\n",
      "(None, 256, 512, 1)\n",
      "(None, 256, 1024, 1)\n",
      "(None, 256, 1024, 1)\n",
      "(None, 256, 1024, 1)\n"
     ]
    }
   ],
   "source": [
    "POOLS = 5\n",
    "inputs = keras.Input((256, 1024, 1))\n",
    "\n",
    "# Encoder - Conv2D gradually down to LSTM\n",
    "# Conv1D didn't work as expected - instead, using conv2d but width of sliding window is 1\n",
    "\n",
    "filter_expand = inputs\n",
    "for i in range(POOLS):\n",
    "    batch_norm = layers.BatchNormalization()(filter_expand)\n",
    "    conv = layers.Conv2D(2**i, (1, 3), (1, 1), padding='same', activation='relu')(batch_norm)\n",
    "    # add\n",
    "    pool = layers.MaxPool2D((1, 2), (1, 2))(conv)   # (add)\n",
    "    filter_expand = layers.Conv2D(2**(i+1), (1, 3), (1, 1), padding='same', activation='relu')(pool)\n",
    "\n",
    "lstm_input = tf.reshape(filter_expand, (-1, 256, 1024))\n",
    "\n",
    "lstm = layers.LSTM(512, return_sequences=True)(lstm_input)\n",
    "dense = layers.Dense(2**10)(lstm)\n",
    "dense_reshaped = tf.reshape(dense, (-1, 256, 1024//2**POOLS, 2**POOLS))\n",
    "\n",
    "conv = dense_reshaped\n",
    "for i in range(POOLS):\n",
    "    batch_norm = layers.BatchNormalization()(conv)\n",
    "    filter_reduce = layers.Conv2D(2**(POOLS - i - 1), (1, 3), (1,1), padding='same', activation='relu')(batch_norm)\n",
    "    depool = layers.UpSampling2D((1, 2))(filter_reduce)\n",
    "    conv = layers.Conv2D(2**(POOLS - i - 1), (1, 3), (1, 1), padding='same', activation='relu')(depool)\n",
    "\n",
    "outputs = layers.Activation('sigmoid')(conv)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"conv1d-lstm\")\n",
    "\n",
    "for layer in model.layers[-10:]:\n",
    "    print(layer.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit = X\n",
    "X_fit = (X_fit - np.min(X_fit))/(np.max(X_fit) - np.min(X_fit))\n",
    "\n",
    "print(\"==================\")\n",
    "print(X_fit.shape)\n",
    "print(\"==================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"lstm_autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_fit, X_fit,\n",
    "        epochs=200,\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARE SPECTROGRAMS IN IMAGES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_example = X[0]\n",
    "\n",
    "plt.imsave(\"INPUT_EXAMPLE.png\", x_example)\n",
    "x_example = np.reshape(x_example, (1, x_example.shape[0], x_example.shape[1], 1))\n",
    "print(x_example.shape)\n",
    "prediction = model.predict(x_example)\n",
    "plt.imsave(\"OUTPUT_EXAMPLE.png\", prediction[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_autoencoder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(postprocessing)\n",
    "out_samp, out_win, out_stride = spec_params\n",
    "audio = postprocessing.reverse_spectrogram(prediction[0, :, :, 0], out_samp, out_win, out_stride)\n",
    "audio = np.reshape(audio, (-1, 1))\n",
    "f_out = open_write(\"test_output_cnn.wav\", 1, 2, 44100)\n",
    "write(f_out, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cc8f092f77316f6fee317f7cf3b29c6fa2dc86058ef2ab119f209826031bc14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
