{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 19:49:18.319149: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-20 19:49:18.511681: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-20 19:49:19.065081: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-20 19:49:19.065152: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-01-20 19:49:19.065158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-01-20 19:49:19.968511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-20 19:49:19.999677: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-20 19:49:20.000244: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# from https://medium.com/ibm-data-ai/memory-hygiene-with-tensorflow-during-model-training-and-deployment-for-inference-45cf49a15688\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(str(gpu))\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpu,[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset from test audio file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STRIDE IS 0.007797696856520386\n",
      "(116, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "xf, X, spec_params = create_dataset('audio/training_audio.wav', 2, 0.5)\n",
    "X = np.abs(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 19:50:09.089502: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-20 19:50:09.091229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-20 19:50:09.091838: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-20 19:50:09.092307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-20 19:50:09.729980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-20 19:50:09.730022: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-01-20 19:50:09.730781: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-20 19:50:09.731250: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-01-20 19:50:09.731347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 64, 4)\n",
      "(None, 256, 64, 4)\n",
      "(None, 256, 64, 2)\n",
      "(None, 256, 128, 2)\n",
      "(None, 256, 128, 2)\n",
      "(None, 256, 128, 2)\n",
      "(None, 256, 128, 1)\n",
      "(None, 256, 256, 1)\n",
      "(None, 256, 256, 1)\n",
      "(None, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "POOLS = 5\n",
    "inputs = keras.Input((256, 256, 1))\n",
    "\n",
    "# Encoder - Conv2D gradually down to LSTM\n",
    "# Conv1D didn't work as expected - instead, using conv2d but width of sliding window is 1\n",
    "\n",
    "filter_expand = inputs\n",
    "for i in range(POOLS):\n",
    "    batch_norm = layers.BatchNormalization()(filter_expand)\n",
    "    conv = layers.Conv2D(2**i, (1, 3), (1, 1), padding='same', activation='relu')(batch_norm)\n",
    "    # add\n",
    "    pool = layers.MaxPool2D((1, 2), (1, 2))(conv)   # (add)\n",
    "    filter_expand = layers.Conv2D(2**(i+1), (1, 3), (1, 1), padding='same', activation='relu')(pool)\n",
    "\n",
    "lstm_input = tf.reshape(filter_expand, (-1, 256, 256))\n",
    "\n",
    "lstm = layers.LSTM(64, return_sequences=True)(lstm_input)\n",
    "dense = layers.Dense(2**8)(lstm)\n",
    "dense_reshaped = tf.reshape(dense, (-1, 256, 256//2**POOLS, 2**POOLS))\n",
    "\n",
    "conv = dense_reshaped\n",
    "for i in range(POOLS):\n",
    "    batch_norm = layers.BatchNormalization()(conv)\n",
    "    filter_reduce = layers.Conv2D(2**(POOLS - i - 1), (1, 3), (1,1), padding='same', activation='relu')(batch_norm)\n",
    "    depool = layers.UpSampling2D((1, 2))(filter_reduce)\n",
    "    conv = layers.Conv2D(2**(POOLS - i - 1), (1, 3), (1, 1), padding='same', activation='relu')(depool)\n",
    "\n",
    "outputs = layers.Activation('sigmoid')(conv)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs, name=\"conv1d-lstm\")\n",
    "\n",
    "for layer in model.layers[-10:]:\n",
    "    print(layer.output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv1d-lstm\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 256, 256, 1)]     0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 256, 1)      4         \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 256, 256, 1)       4         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 256, 128, 1)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 256, 128, 2)       8         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256, 128, 2)      8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 256, 128, 2)       14        \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 256, 64, 2)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 256, 64, 4)        28        \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 256, 64, 4)       16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 256, 64, 4)        52        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 256, 32, 4)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 256, 32, 8)        104       \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 256, 32, 8)       32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 256, 32, 8)        200       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 256, 16, 8)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 256, 16, 16)       400       \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 256, 16, 16)      64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 256, 16, 16)       784       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 256, 8, 16)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 256, 8, 32)        1568      \n",
      "                                                                 \n",
      " tf.reshape (TFOpLambda)     (None, 256, 256)          0         \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 256, 512)          1574912   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256, 128)          65664     \n",
      "                                                                 \n",
      " tf.reshape_1 (TFOpLambda)   (None, 256, 8, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 256, 8, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 256, 8, 16)        1552      \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2D  (None, 256, 16, 16)      0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 256, 16, 16)       784       \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 256, 16, 16)      64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 256, 16, 8)        392       \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 256, 32, 8)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 256, 32, 8)        200       \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 256, 32, 8)       32        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 256, 32, 4)        100       \n",
      "                                                                 \n",
      " up_sampling2d_2 (UpSampling  (None, 256, 64, 4)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 256, 64, 4)        52        \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 256, 64, 4)       16        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 256, 64, 2)        26        \n",
      "                                                                 \n",
      " up_sampling2d_3 (UpSampling  (None, 256, 128, 2)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 256, 128, 2)       14        \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 256, 128, 2)      8         \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 256, 128, 1)       7         \n",
      "                                                                 \n",
      " up_sampling2d_4 (UpSampling  (None, 256, 256, 1)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 256, 256, 1)       4         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 256, 256, 1)       0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,647,241\n",
      "Trainable params: 1,647,055\n",
      "Non-trainable params: 186\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "(116, 256, 256, 1)\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "X_fit = X\n",
    "X_fit = (X_fit - np.min(X_fit))/(np.max(X_fit) - np.min(X_fit))\n",
    "X_fit = tf.expand_dims(X_fit, -1)\n",
    "print(\"==================\")\n",
    "print(X_fit.shape)\n",
    "print(\"==================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"lstm_autoencoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-20 19:51:38.791399: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8700\n",
      "2023-01-20 19:51:39.976349: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-01-20 19:51:40.656793: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-01-20 19:51:40.784606: W tensorflow/core/framework/op_kernel.cc:1768] INVALID_ARGUMENT: required broadcastable shapes\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'mean_squared_error/SquaredDifference' defined at (most recent call last):\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/nash/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/nash/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_6159/2383519506.py\", line 1, in <module>\n      model.fit(X_fit, X_fit,\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/losses.py\", line 1486, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\nNode: 'mean_squared_error/SquaredDifference'\nrequired broadcastable shapes\n\t [[{{node mean_squared_error/SquaredDifference}}]] [Op:__inference_train_function_6410]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_fit, X_fit,\n\u001b[1;32m      2\u001b[0m         epochs\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m         shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'mean_squared_error/SquaredDifference' defined at (most recent call last):\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/nash/.local/lib/python3.8/site-packages/traitlets/config/application.py\", line 982, in launch_instance\n      app.start()\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/nash/.local/lib/python3.8/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/asyncio/base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"/home/nash/miniconda3/envs/tf/lib/python3.8/asyncio/events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/nash/.local/lib/python3.8/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2940, in run_cell\n      result = self._run_cell(\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2995, in _run_cell\n      return runner(coro)\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3194, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3373, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/nash/.local/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3433, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_6159/2383519506.py\", line 1, in <module>\n      model.fit(X_fit, X_fit,\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/engine/compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/nash/.local/lib/python3.8/site-packages/keras/losses.py\", line 1486, in mean_squared_error\n      return backend.mean(tf.math.squared_difference(y_pred, y_true), axis=-1)\nNode: 'mean_squared_error/SquaredDifference'\nrequired broadcastable shapes\n\t [[{{node mean_squared_error/SquaredDifference}}]] [Op:__inference_train_function_6410]"
     ]
    }
   ],
   "source": [
    "model.fit(X_fit, X_fit,\n",
    "        epochs=200,\n",
    "        shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COMPARE SPECTROGRAMS IN IMAGES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_example = X[0]\n",
    "\n",
    "plt.imsave(\"INPUT_EXAMPLE.png\", x_example)\n",
    "x_example = np.reshape(x_example, (1, x_example.shape[0], x_example.shape[1], 1))\n",
    "print(x_example.shape)\n",
    "prediction = model.predict(x_example)\n",
    "plt.imsave(\"OUTPUT_EXAMPLE.png\", prediction[0, :, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"cnn_autoencoder\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import postprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(postprocessing)\n",
    "out_samp, out_win, out_stride = spec_params\n",
    "audio = postprocessing.reverse_spectrogram(prediction[0, :, :, 0], out_samp, out_win, out_stride)\n",
    "audio = np.reshape(audio, (-1, 1))\n",
    "f_out = open_write(\"test_output_cnn.wav\", 1, 2, 44100)\n",
    "write(f_out, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cc8f092f77316f6fee317f7cf3b29c6fa2dc86058ef2ab119f209826031bc14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
