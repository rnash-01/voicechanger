{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 23:04:01.478556: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-31 23:04:02.084255: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-12-31 23:04:03.901343: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-31 23:04:03.901512: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-12-31 23:04:03.901522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-12-31 23:04:07.129942: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-31 23:04:07.310924: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-31 23:04:07.311558: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# from https://medium.com/ibm-data-ai/memory-hygiene-with-tensorflow-during-model-training-and-deployment-for-inference-45cf49a15688\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    for gpu in gpus:\n",
    "        print(str(gpu))\n",
    "        tf.config.experimental.set_virtual_device_configuration(gpu,[tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\n",
    "\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create dataset from test audio file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116, 1024, 169)\n"
     ]
    }
   ],
   "source": [
    "xf, X = create_dataset('audio/training_audio.wav', 2, 0.5)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some 'blocks' of NN code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(inputs, input_shape, channels, block_name='ResBlock'):\n",
    "    \n",
    "    conv2d_1 = keras.layers.Conv2D(channels, kernel_size=(10, 1), padding='same', input_shape=input_shape)(inputs)\n",
    "\n",
    "    batch_norm_1 = keras.layers.BatchNormalization()(conv2d_1)\n",
    "    activation_1 = keras.layers.Activation('relu')(batch_norm_1)\n",
    "\n",
    "    conv2d_2 = keras.layers.Conv2D(channels, kernel_size=10, padding='same')(activation_1)\n",
    "    batch_norm_2 = keras.layers.BatchNormalization()(conv2d_2)\n",
    "\n",
    "    add = keras.layers.Add()([batch_norm_2, inputs])\n",
    "    activation_2 = keras.layers.Activation('relu')(add)\n",
    "    return activation_2\n",
    "\n",
    "def downscale_block(inputs, num_filters, block_name='DownscaleBlock'):\n",
    "\n",
    "    downscale = keras.layers.Conv2D(num_filters, kernel_size=(10, 1), padding='same')(inputs)\n",
    "    batch_norm = keras.layers.BatchNormalization()(downscale)\n",
    "    activation = keras.layers.Activation('relu')(batch_norm)\n",
    "    \n",
    "    return activation\n",
    "\n",
    "def upscale_block(inputs, target_size, num_filters, block_name='UpscaleBlock'):\n",
    "    \n",
    "    _, height, timesteps, channels = inputs.shape\n",
    "    upscale = keras.layers.Conv2DTranspose(num_filters, (target_size - height + 1, 1))(inputs)\n",
    "    batch_norm = keras.layers.BatchNormalization()(upscale)\n",
    "    activation = keras.layers.Activation('relu')(batch_norm)\n",
    "\n",
    "    return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_lstm_decoder(spec_shape, start_filters):\n",
    "    input_length =  spec_shape[0]\n",
    "    time_steps = spec_shape[1]\n",
    "    input_shape = (input_length, time_steps, 1)\n",
    "\n",
    "    # Encoder\n",
    "    inputs = keras.layers.Input(input_shape)                                                                    # input_length is power of two\n",
    "    print(input_shape)\n",
    "\n",
    "    res_block_1 = residual_block(inputs, input_shape, 1, 'ResBlock1')\n",
    "    max_pool_1 = keras.layers.MaxPool2D(pool_size=(2,1))(res_block_1)                 # (input_length/2,)\n",
    "    down_scale_1 = downscale_block(max_pool_1, start_filters, 'DownscaleBlock1')\n",
    "    print(down_scale_1.shape)\n",
    "\n",
    "    res_block_2 = residual_block(down_scale_1, (input_length//2, time_steps, start_filters), start_filters, 'ResBlock2')\n",
    "    max_pool_2 = keras.layers.MaxPool2D(pool_size=(2,1))(res_block_2)                 # (input_length/2,)\n",
    "    down_scale_2 = downscale_block(max_pool_2, start_filters * 2, 'DownscaleBlock2')\n",
    "    print(down_scale_2.shape)\n",
    "\n",
    "    res_block_3 = residual_block(down_scale_2, (input_length//4, time_steps, start_filters*2), start_filters * 2, 'ResBlock3')\n",
    "    max_pool_3 = keras.layers.MaxPool2D(pool_size=(2,1))(res_block_2)                 # (input_length/2,)\n",
    "    down_scale_3 = downscale_block(max_pool_3, start_filters * 4, 'DownscaleBlock3')\n",
    "    print(down_scale_3.shape)\n",
    "\n",
    "    res_block_4 = residual_block(down_scale_3, (input_length//8, time_steps, start_filters*4), start_filters * 4, 'ResBlock4')\n",
    "    max_pool_4 = keras.layers.MaxPool2D(pool_size=(2,1))(res_block_4)                 # (input_length/2,)\n",
    "    down_scale_4 = downscale_block(max_pool_4, start_filters * 8, 'DownscaleBlock4')\n",
    "    print(down_scale_4.shape)\n",
    "\n",
    "    # Decoder\n",
    "    _, height, timesteps, channels = down_scale_4.shape\n",
    "    # down_scale_4_flat = tf.reshape(down_scale_4, (-1, timesteps, height * channels))\n",
    "    down_scale_4_flat = keras.layers.Reshape((timesteps, height * channels))(down_scale_4)\n",
    "    print(f\"down_scale_4 {down_scale_4_flat.shape}\")\n",
    "    lstm = keras.layers.LSTM(height * channels, return_sequences=True)(down_scale_4_flat)    # todo CHANGE N UNITS\n",
    "\n",
    "    print(f\"LSTM: {lstm.shape}\")\n",
    "\n",
    "    # lstm_unflatten = tf.reshape(lstm, (-1, height, timesteps, channels))\n",
    "    lstm_unflatten = keras.layers.Reshape((height, timesteps, channels))(lstm)\n",
    "    print(f\"Unflattened LSTM: {lstm_unflatten.shape}\")\n",
    "\n",
    "    upscale_1 = upscale_block(lstm_unflatten, input_length//8, start_filters * 4, 'Upscale1')\n",
    "    # print(upscale_1.shape)\n",
    "    upscale_2 = upscale_block(upscale_1, input_length//4, start_filters * 2, 'Upscale2')\n",
    "    # print(upscale_2.shape)\n",
    "    upscale_3 = upscale_block(upscale_2, input_length//2, start_filters, 'Upscale3')\n",
    "    # print(upscale_3.shape)\n",
    "    upscale_4 = upscale_block(upscale_3, input_length, 1, 'Upscale4')\n",
    "    # print(upscale_4.shape)\n",
    "\n",
    "    _, height, timesteps, channels = upscale_4.shape\n",
    "    # outputs = tf.reshape(upscale_4, (-1, height, timesteps))\n",
    "    outputs = keras.layers.Reshape((height, timesteps))(upscale_4)\n",
    "    # print(outputs.shape)\n",
    "    \n",
    "    # outputs = keras.layers.Dense(input_length, activation='sigmoid')(upscale_4_flatten)\n",
    "    \n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================\n",
      "(2, 1024, 169)\n",
      "==================\n",
      "(1024, 169, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 23:05:14.319859: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-31 23:05:14.325499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-31 23:05:14.326647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-31 23:05:14.327648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-31 23:05:17.454804: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-31 23:05:17.454843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1700] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2022-12-31 23:05:17.455780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-31 23:05:17.457100: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:966] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-12-31 23:05:17.458091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1616] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 512, 169, 8)\n",
      "(None, 256, 169, 16)\n",
      "(None, 256, 169, 32)\n",
      "(None, 128, 169, 64)\n",
      "down_scale_4 (None, 169, 8192)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 23:05:28.165593: W tensorflow/core/common_runtime/bfc_allocator.cc:479] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.00GiB (rounded to 1073741824)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-12-31 23:05:28.165767: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] BFCAllocator dump for GPU_0_bfc\n",
      "2022-12-31 23:05:28.165789: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (256): \tTotal Chunks: 93, Chunks in use: 93. 23.2KiB allocated for chunks. 23.2KiB in use in bin. 4.8KiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165798: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (512): \tTotal Chunks: 2, Chunks in use: 2. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 720B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165805: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165817: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2048): \tTotal Chunks: 1, Chunks in use: 1. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.5KiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165829: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 5.0KiB allocated for chunks. 5.0KiB in use in bin. 5.0KiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165842: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8192): \tTotal Chunks: 4, Chunks in use: 2. 44.0KiB allocated for chunks. 20.0KiB in use in bin. 20.0KiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165857: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 25.0KiB allocated for chunks. 25.0KiB in use in bin. 25.0KiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165867: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (32768): \tTotal Chunks: 1, Chunks in use: 1. 40.0KiB allocated for chunks. 40.0KiB in use in bin. 40.0KiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165873: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (65536): \tTotal Chunks: 5, Chunks in use: 2. 410.0KiB allocated for chunks. 180.0KiB in use in bin. 180.0KiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165879: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165886: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (262144): \tTotal Chunks: 1, Chunks in use: 1. 400.0KiB allocated for chunks. 400.0KiB in use in bin. 400.0KiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165892: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (524288): \tTotal Chunks: 1, Chunks in use: 0. 640.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165897: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165902: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165907: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165911: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165916: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165921: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165926: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165941: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165948: I tensorflow/core/common_runtime/bfc_allocator.cc:1040] Bin (268435456): \tTotal Chunks: 4, Chunks in use: 3. 4.00GiB allocated for chunks. 3.00GiB in use in bin. 3.00GiB client-requested in use in bin.\n",
      "2022-12-31 23:05:28.165954: I tensorflow/core/common_runtime/bfc_allocator.cc:1056] Bin for 1.00GiB was 256.00MiB, Chunk State: \n",
      "2022-12-31 23:05:28.165970: I tensorflow/core/common_runtime/bfc_allocator.cc:1062]   Size: 1022.45MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 1.00GiB | Requested Size: 1.00GiB | in_use: 1 | bin_num: -1\n",
      "2022-12-31 23:05:28.165974: I tensorflow/core/common_runtime/bfc_allocator.cc:1069] Next region of size 4294967296\n",
      "2022-12-31 23:05:28.166063: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800000 of size 1280 next 1\n",
      "2022-12-31 23:05:28.166075: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800500 of size 256 next 2\n",
      "2022-12-31 23:05:28.166079: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800600 of size 256 next 3\n",
      "2022-12-31 23:05:28.166083: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800700 of size 256 next 5\n",
      "2022-12-31 23:05:28.166087: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800800 of size 256 next 4\n",
      "2022-12-31 23:05:28.166091: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800900 of size 256 next 6\n",
      "2022-12-31 23:05:28.166095: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800a00 of size 256 next 7\n",
      "2022-12-31 23:05:28.166098: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800b00 of size 256 next 8\n",
      "2022-12-31 23:05:28.166102: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800c00 of size 256 next 9\n",
      "2022-12-31 23:05:28.166106: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800d00 of size 256 next 10\n",
      "2022-12-31 23:05:28.166110: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800e00 of size 256 next 11\n",
      "2022-12-31 23:05:28.166114: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511800f00 of size 256 next 12\n",
      "2022-12-31 23:05:28.166118: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801000 of size 256 next 13\n",
      "2022-12-31 23:05:28.166121: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801100 of size 256 next 15\n",
      "2022-12-31 23:05:28.166125: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801200 of size 256 next 16\n",
      "2022-12-31 23:05:28.166129: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801300 of size 256 next 14\n",
      "2022-12-31 23:05:28.166133: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801400 of size 256 next 17\n",
      "2022-12-31 23:05:28.166137: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801500 of size 256 next 20\n",
      "2022-12-31 23:05:28.166141: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801600 of size 256 next 21\n",
      "2022-12-31 23:05:28.166144: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801700 of size 256 next 18\n",
      "2022-12-31 23:05:28.166149: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801800 of size 512 next 19\n",
      "2022-12-31 23:05:28.166153: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801a00 of size 256 next 23\n",
      "2022-12-31 23:05:28.166156: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801b00 of size 256 next 24\n",
      "2022-12-31 23:05:28.166160: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801c00 of size 256 next 22\n",
      "2022-12-31 23:05:28.166164: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801d00 of size 256 next 25\n",
      "2022-12-31 23:05:28.166171: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801e00 of size 256 next 28\n",
      "2022-12-31 23:05:28.166177: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511801f00 of size 256 next 29\n",
      "2022-12-31 23:05:28.166181: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802000 of size 256 next 26\n",
      "2022-12-31 23:05:28.166185: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802100 of size 512 next 27\n",
      "2022-12-31 23:05:28.166189: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802300 of size 256 next 31\n",
      "2022-12-31 23:05:28.166193: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802400 of size 256 next 32\n",
      "2022-12-31 23:05:28.166197: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802500 of size 256 next 30\n",
      "2022-12-31 23:05:28.166200: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802600 of size 256 next 33\n",
      "2022-12-31 23:05:28.166204: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802700 of size 256 next 36\n",
      "2022-12-31 23:05:28.166208: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802800 of size 256 next 37\n",
      "2022-12-31 23:05:28.166212: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802900 of size 256 next 38\n",
      "2022-12-31 23:05:28.166216: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802a00 of size 256 next 41\n",
      "2022-12-31 23:05:28.166219: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802b00 of size 256 next 39\n",
      "2022-12-31 23:05:28.166223: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802c00 of size 256 next 40\n",
      "2022-12-31 23:05:28.166227: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802d00 of size 256 next 44\n",
      "2022-12-31 23:05:28.166231: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802e00 of size 256 next 45\n",
      "2022-12-31 23:05:28.166235: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511802f00 of size 256 next 46\n",
      "2022-12-31 23:05:28.166238: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803000 of size 256 next 47\n",
      "2022-12-31 23:05:28.166242: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803100 of size 256 next 50\n",
      "2022-12-31 23:05:28.166246: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803200 of size 256 next 48\n",
      "2022-12-31 23:05:28.166250: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803300 of size 256 next 49\n",
      "2022-12-31 23:05:28.166254: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803400 of size 256 next 53\n",
      "2022-12-31 23:05:28.166257: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803500 of size 256 next 54\n",
      "2022-12-31 23:05:28.166261: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803600 of size 256 next 55\n",
      "2022-12-31 23:05:28.166265: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803700 of size 256 next 56\n",
      "2022-12-31 23:05:28.166269: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803800 of size 256 next 57\n",
      "2022-12-31 23:05:28.166273: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803900 of size 256 next 34\n",
      "2022-12-31 23:05:28.166277: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511803a00 of size 2560 next 35\n",
      "2022-12-31 23:05:28.166284: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804400 of size 256 next 58\n",
      "2022-12-31 23:05:28.166287: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804500 of size 256 next 61\n",
      "2022-12-31 23:05:28.166291: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804600 of size 256 next 62\n",
      "2022-12-31 23:05:28.166295: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804700 of size 256 next 63\n",
      "2022-12-31 23:05:28.166299: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804800 of size 256 next 64\n",
      "2022-12-31 23:05:28.166304: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804900 of size 256 next 67\n",
      "2022-12-31 23:05:28.166308: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804a00 of size 256 next 65\n",
      "2022-12-31 23:05:28.166312: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804b00 of size 256 next 66\n",
      "2022-12-31 23:05:28.166315: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804c00 of size 256 next 70\n",
      "2022-12-31 23:05:28.166319: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804d00 of size 256 next 71\n",
      "2022-12-31 23:05:28.166323: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804e00 of size 256 next 72\n",
      "2022-12-31 23:05:28.166327: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511804f00 of size 256 next 73\n",
      "2022-12-31 23:05:28.166330: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805000 of size 256 next 74\n",
      "2022-12-31 23:05:28.166334: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805100 of size 256 next 75\n",
      "2022-12-31 23:05:28.166338: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805200 of size 256 next 77\n",
      "2022-12-31 23:05:28.166342: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805300 of size 256 next 78\n",
      "2022-12-31 23:05:28.166346: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805400 of size 256 next 79\n",
      "2022-12-31 23:05:28.166349: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805500 of size 256 next 80\n",
      "2022-12-31 23:05:28.166353: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805600 of size 256 next 81\n",
      "2022-12-31 23:05:28.166357: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805700 of size 256 next 84\n",
      "2022-12-31 23:05:28.166361: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805800 of size 256 next 82\n",
      "2022-12-31 23:05:28.166365: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805900 of size 256 next 83\n",
      "2022-12-31 23:05:28.166368: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805a00 of size 256 next 87\n",
      "2022-12-31 23:05:28.166372: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805b00 of size 256 next 88\n",
      "2022-12-31 23:05:28.166376: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805c00 of size 256 next 89\n",
      "2022-12-31 23:05:28.166380: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805d00 of size 256 next 90\n",
      "2022-12-31 23:05:28.166384: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805e00 of size 256 next 93\n",
      "2022-12-31 23:05:28.166388: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511805f00 of size 256 next 91\n",
      "2022-12-31 23:05:28.166391: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806000 of size 256 next 92\n",
      "2022-12-31 23:05:28.166395: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806100 of size 256 next 96\n",
      "2022-12-31 23:05:28.166399: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806200 of size 256 next 97\n",
      "2022-12-31 23:05:28.166403: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806300 of size 256 next 98\n",
      "2022-12-31 23:05:28.166406: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806400 of size 256 next 99\n",
      "2022-12-31 23:05:28.166410: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806500 of size 256 next 100\n",
      "2022-12-31 23:05:28.166414: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806600 of size 256 next 101\n",
      "2022-12-31 23:05:28.166418: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806700 of size 256 next 104\n",
      "2022-12-31 23:05:28.166422: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806800 of size 256 next 105\n",
      "2022-12-31 23:05:28.166426: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806900 of size 256 next 106\n",
      "2022-12-31 23:05:28.166430: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806a00 of size 256 next 107\n",
      "2022-12-31 23:05:28.166434: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806b00 of size 256 next 52\n",
      "2022-12-31 23:05:28.166438: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511806c00 of size 5120 next 51\n",
      "2022-12-31 23:05:28.166442: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511808000 of size 256 next 110\n",
      "2022-12-31 23:05:28.166446: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511808100 of size 256 next 108\n",
      "2022-12-31 23:05:28.166449: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511808200 of size 256 next 109\n",
      "2022-12-31 23:05:28.166453: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511808300 of size 256 next 113\n",
      "2022-12-31 23:05:28.166457: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 511808400 of size 9472 next 59\n",
      "2022-12-31 23:05:28.166461: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 51180a900 of size 10240 next 60\n",
      "2022-12-31 23:05:28.166465: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 51180d100 of size 15104 next 43\n",
      "2022-12-31 23:05:28.166469: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511810c00 of size 25600 next 42\n",
      "2022-12-31 23:05:28.166473: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511817000 of size 10240 next 76\n",
      "2022-12-31 23:05:28.166477: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 511819800 of size 81920 next 86\n",
      "2022-12-31 23:05:28.166481: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 51182d800 of size 40960 next 85\n",
      "2022-12-31 23:05:28.166485: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 511837800 of size 71680 next 69\n",
      "2022-12-31 23:05:28.166489: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511849000 of size 102400 next 68\n",
      "2022-12-31 23:05:28.166496: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 511862000 of size 81920 next 103\n",
      "2022-12-31 23:05:28.166500: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 511876000 of size 81920 next 102\n",
      "2022-12-31 23:05:28.166504: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 51188a000 of size 655360 next 95\n",
      "2022-12-31 23:05:28.166508: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 51192a000 of size 409600 next 94\n",
      "2022-12-31 23:05:28.166512: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 51198e000 of size 1073741824 next 114\n",
      "2022-12-31 23:05:28.166516: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 55198e000 of size 1073741824 next 112\n",
      "2022-12-31 23:05:28.166520: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] InUse at 59198e000 of size 1073741824 next 111\n",
      "2022-12-31 23:05:28.166525: I tensorflow/core/common_runtime/bfc_allocator.cc:1089] Free  at 5d198e000 of size 1072111616 next 18446744073709551615\n",
      "2022-12-31 23:05:28.166529: I tensorflow/core/common_runtime/bfc_allocator.cc:1094]      Summary of in-use Chunks by size: \n",
      "2022-12-31 23:05:28.166537: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 93 Chunks of size 256 totalling 23.2KiB\n",
      "2022-12-31 23:05:28.166542: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2022-12-31 23:05:28.166547: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-12-31 23:05:28.166552: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 2560 totalling 2.5KiB\n",
      "2022-12-31 23:05:28.166556: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 5120 totalling 5.0KiB\n",
      "2022-12-31 23:05:28.166561: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 2 Chunks of size 10240 totalling 20.0KiB\n",
      "2022-12-31 23:05:28.166566: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 25600 totalling 25.0KiB\n",
      "2022-12-31 23:05:28.166572: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 40960 totalling 40.0KiB\n",
      "2022-12-31 23:05:28.166579: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 81920 totalling 80.0KiB\n",
      "2022-12-31 23:05:28.166583: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 102400 totalling 100.0KiB\n",
      "2022-12-31 23:05:28.166588: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 1 Chunks of size 409600 totalling 400.0KiB\n",
      "2022-12-31 23:05:28.166593: I tensorflow/core/common_runtime/bfc_allocator.cc:1097] 3 Chunks of size 1073741824 totalling 3.00GiB\n",
      "2022-12-31 23:05:28.166597: I tensorflow/core/common_runtime/bfc_allocator.cc:1101] Sum Total of in-use chunks: 3.00GiB\n",
      "2022-12-31 23:05:28.166603: I tensorflow/core/common_runtime/bfc_allocator.cc:1103] total_region_allocated_bytes_: 4294967296 memory_limit_: 4294967296 available bytes: 0 curr_region_allocation_bytes_: 8589934592\n",
      "2022-12-31 23:05:28.166614: I tensorflow/core/common_runtime/bfc_allocator.cc:1109] Stats: \n",
      "Limit:                      4294967296\n",
      "InUse:                      3221940224\n",
      "MaxInUse:                   3221940224\n",
      "NumAllocs:                         173\n",
      "MaxAllocSize:               1073741824\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-12-31 23:05:28.166624: W tensorflow/core/common_runtime/bfc_allocator.cc:491] ****************************************************************************________________________\n",
      "2022-12-31 23:05:28.168858: W tensorflow/core/framework/op_kernel.cc:1768] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mprint\u001b[39m(X_fit\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m==================\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m model \u001b[39m=\u001b[39m encoder_lstm_decoder(X_fit[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mshape, \u001b[39m8\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m1e-3\u001b[39m),\n\u001b[1;32m      8\u001b[0m               loss\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(),\n\u001b[1;32m      9\u001b[0m               metrics\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mBinaryAccuracy(),\n\u001b[1;32m     10\u001b[0m                        tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mFalseNegatives()])\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCOMPILATION FINISHED\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [5], line 35\u001b[0m, in \u001b[0;36mencoder_lstm_decoder\u001b[0;34m(spec_shape, start_filters)\u001b[0m\n\u001b[1;32m     33\u001b[0m down_scale_4_flat \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mReshape((timesteps, height \u001b[39m*\u001b[39m channels))(down_scale_4)\n\u001b[1;32m     34\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdown_scale_4 \u001b[39m\u001b[39m{\u001b[39;00mdown_scale_4_flat\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m lstm \u001b[39m=\u001b[39m keras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mLSTM(height \u001b[39m*\u001b[39;49m channels, return_sequences\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)(down_scale_4_flat)    \u001b[39m# todo CHANGE N UNITS\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mLSTM: \u001b[39m\u001b[39m{\u001b[39;00mlstm\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[39m# lstm_unflatten = tf.reshape(lstm, (-1, height, timesteps, channels))\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/layers/rnn/base_rnn.py:553\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m inputs, initial_state, constants \u001b[39m=\u001b[39m rnn_utils\u001b[39m.\u001b[39mstandardize_args(\n\u001b[1;32m    549\u001b[0m     inputs, initial_state, constants, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_constants\n\u001b[1;32m    550\u001b[0m )\n\u001b[1;32m    552\u001b[0m \u001b[39mif\u001b[39;00m initial_state \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m constants \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 553\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(inputs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    555\u001b[0m \u001b[39m# If any of `initial_state` or `constants` are specified and are Keras\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39m# tensors, then add them to the inputs and temporarily modify the\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39m# input_spec to include them.\u001b[39;00m\n\u001b[1;32m    559\u001b[0m additional_inputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/keras/backend.py:2061\u001b[0m, in \u001b[0;36mRandomGenerator.random_normal\u001b[0;34m(self, shape, mean, stddev, dtype, nonce)\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[39mif\u001b[39;00m nonce:\n\u001b[1;32m   2060\u001b[0m         seed \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mstateless_fold_in(seed, nonce)\n\u001b[0;32m-> 2061\u001b[0m     \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mstateless_normal(\n\u001b[1;32m   2062\u001b[0m         shape\u001b[39m=\u001b[39;49mshape, mean\u001b[39m=\u001b[39;49mmean, stddev\u001b[39m=\u001b[39;49mstddev, dtype\u001b[39m=\u001b[39;49mdtype, seed\u001b[39m=\u001b[39;49mseed\n\u001b[1;32m   2063\u001b[0m     )\n\u001b[1;32m   2064\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mnormal(\n\u001b[1;32m   2065\u001b[0m     shape\u001b[39m=\u001b[39mshape,\n\u001b[1;32m   2066\u001b[0m     mean\u001b[39m=\u001b[39mmean,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2069\u001b[0m     seed\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_legacy_seed(),\n\u001b[1;32m   2070\u001b[0m )\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "X_fit = X[:2]\n",
    "\n",
    "print(\"==================\")\n",
    "print(X_fit.shape)\n",
    "print(\"==================\")\n",
    "model = encoder_lstm_decoder(X_fit[0].shape, 8)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                       tf.keras.metrics.FalseNegatives()])\n",
    "print(\"COMPILATION FINISHED\")\n",
    "print(model.summary())\n",
    "# model.fit(x=X, y=X, epochs=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cc8f092f77316f6fee317f7cf3b29c6fa2dc86058ef2ab119f209826031bc14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
